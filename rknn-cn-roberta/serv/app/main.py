import uvicorn
from typing import Union
from fastapi import FastAPI
from rknnlite.api import RKNNLite
from pydantic import BaseModel, Field
from typing import AsyncGenerator
import asyncio
from contextlib import asynccontextmanager
from typing import List
from concurrent.futures import ThreadPoolExecutor
import threading
import numpy as np
from transformers import AutoTokenizer



# æ•°æ®æ¨¡å‹
class TextRequest(BaseModel):
    text: str = Field(..., min_length=1, max_length=1000, example="Hello World")

class ApiResponse(BaseModel):
    message: str
    data: str


class NPUCorePool:
    def __init__(self, core_ids: List[int]):
        self.available_cores = core_ids
        self.lock = threading.Lock()
        self.pool = {}
        
        # åˆå§‹åŒ–æ‰€æœ‰NPUæ ¸å¿ƒ
        for core_id in core_ids:
            rknn = RKNNLite()
            ret = rknn.load_rknn("/home/proembed/emotion/cn_roberta_v1.rknn")
            if ret != 0:
                raise RuntimeError(f"Core {core_id} åˆå§‹åŒ–å¤±è´¥")
            rknn.init_runtime(core_mask=core_id)
            tokenizer = AutoTokenizer.from_pretrained("/home/proembed/emotion/")

            self.pool[core_id] = {
                "rknn": rknn,
                "tokenizer": tokenizer,
                "in_use": False
            }
            print(f"NPUæ ¸å¿ƒ {core_id} åˆå§‹åŒ–å®Œæˆ")

    def acquire_core(self):
        with self.lock:
            for core_id, status in self.pool.items():
                if not status["in_use"]:
                    status["in_use"] = True
                    return core_id, status["rknn"], status["tokenizer"]
            return None, None, None  # æ— å¯ç”¨æ ¸å¿ƒ

    def release_core(self, core_id: int):
        with self.lock:
            self.pool[core_id]["in_use"] = False

    async def shutdown(self):
        """å¼‚æ­¥å®‰å…¨å…³é—­æ‰€æœ‰æ ¸å¿ƒ"""
        release_tasks = []
        for core_id in self.pool:
            task = asyncio.create_task(self._release_core_async(core_id))
            release_tasks.append(task)
        await asyncio.gather(*release_tasks)

    async def _release_core_async(self, core_id: int):
        """å¼‚æ­¥é‡Šæ”¾å•ä¸ªæ ¸å¿ƒ"""
        try:
            await asyncio.get_event_loop().run_in_executor(
                None, 
                self.pool[core_id]["rknn"].release
            )
        except Exception as e:
            print(f"æ ¸å¿ƒ {core_id} é‡Šæ”¾å¼‚å¸¸: {str(e)}")


class InferenceWorker:
    def __init__(self, core_pool: NPUCorePool):
        self.core_pool = core_pool
        self.executor = ThreadPoolExecutor(max_workers=3)  # æ¯ä¸ªæ ¸å¿ƒä¸€ä¸ªçº¿ç¨‹
        self.M = {0:'è´Ÿå‘', 1: 'ä¸­æ€§',  2:'æ­£å‘' }

    async def predict(self, text: str):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self._sync_predict,
            text
        )

    def _sync_predict(self, text: str):
        core_id, rknn, tokenizer = self.core_pool.acquire_core()
        if not rknn:
            raise RuntimeError("æ‰€æœ‰NPUæ ¸å¿ƒå¿™")

        try:
            # é¢„å¤„ç†
            inputs = tokenizer(text, padding="max_length", truncation=True, max_length=128, return_tensors="np")
            input_ids = inputs["input_ids"].astype(np.int64)
            attention_mask = inputs["attention_mask"].astype(np.int64)
            # æ¨ç†
            outputs = rknn.inference(inputs=[input_ids, attention_mask])
            # åå¤„ç†
            exp_values = np.exp(outputs[0] - np.max(outputs[0], axis=1, keepdims=True))
            softmax_array = exp_values / np.sum(exp_values, axis=1, keepdims=True)
            idx = np.argmax(softmax_array)
            return self.M[idx]
        finally:
            self.core_pool.release_core(core_id)

# å…¨å±€èµ„æºç®¡ç†å™¨
npu_pool: Union[NPUCorePool, None] = None
worker: Union[InferenceWorker , None] = None


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """ç®¡ç†åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"""
    global npu_pool, worker
    
    # åˆå§‹åŒ–é˜¶æ®µ
    try:
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–NPUèµ„æº...")
        npu_pool = NPUCorePool(core_ids=[
            RKNNLite.NPU_CORE_0, 
            RKNNLite.NPU_CORE_1,
            RKNNLite.NPU_CORE_2
        ])
        worker = InferenceWorker(npu_pool)
        
        # é¢„çƒ­æ‰€æœ‰æ ¸å¿ƒï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
        async def warmup():
            tasks = [worker.predict("é¢„çƒ­æ–‡æœ¬") for _ in range(3)]
            await asyncio.gather(*tasks)
        await warmup()

        yield  # è¿›å…¥è¿è¡Œé˜¶æ®µ
        
    finally:
        # æ¸…ç†é˜¶æ®µ
        print("\nğŸ›‘ æ­£åœ¨é‡Šæ”¾NPUèµ„æº...")
        if npu_pool:
            await npu_pool.shutdown()
        print("âœ… èµ„æºé‡Šæ”¾å®Œæˆ")

app = FastAPI(lifespan=lifespan)


@app.post("/predict")
async def predict(request: TextRequest):
    ret_str = await worker.predict(request.text)
    return ApiResponse(
        message="Success",
        data=ret_str
    )


if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8080
    )
